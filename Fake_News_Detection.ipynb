{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNJN0dA96HqU+dHSMG5zaph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arwin-K/Fake-News-Detection/blob/main/Fake_News_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing Libraries**"
      ],
      "metadata": {
        "id": "da3WShrzq14H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wv7DW2XBCwf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Sklearn for Traditional ML\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Deep Learning (Transformers)\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "# NLTK Resources\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Set Seed for Reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing dataset through Kaggle\n",
        "!pip install -q kaggle"
      ],
      "metadata": {
        "id": "rb5hbcPPBNEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "l6Kg8t3anFSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset\n",
        "!kaggle datasets download -d aadyasingh55/fake-news-classification\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip fake-news-classification.zip"
      ],
      "metadata": {
        "id": "SpJDioL9o5y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Importing and Standardizing Kaggle Dataset**"
      ],
      "metadata": {
        "id": "EBkYKzCUrBME"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the training set\n",
        "train_df = pd.read_csv('train (2).csv', sep=';')\n",
        "\n",
        "# Loading the test set\n",
        "test_df = pd.read_csv('test (1).csv', sep=';')\n",
        "\n",
        "# Loading the evaluation set\n",
        "eval_df = pd.read_csv('evaluation.csv', sep=';')"
      ],
      "metadata": {
        "id": "ytt5jIH_o_RL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming files for easier naming system convention\n",
        "import os\n",
        "os.rename('train (2).csv', 'fake_news_detection_train.csv')\n",
        "os.rename('test (1).csv', 'fake_news_detection_test.csv')\n",
        "os.rename('evaluation.csv', 'fake_news_detection_evaluation.csv')"
      ],
      "metadata": {
        "id": "aDlEon4Sp0jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing dataset sizes and head columns\n",
        "print(f\"Training Dataset Shape: {train_df.shape}\")\n",
        "train_df.head()\n",
        "\n",
        "print(f\"Testing Dataset Shape: {test_df.shape}\")\n",
        "test_df.head()\n",
        "\n",
        "print(f\"Evaluation Dataset Shape: {eval_df.shape}\")\n",
        "eval_df.head()"
      ],
      "metadata": {
        "id": "6MDfLS-oqNTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying Traditional Machine Learning Models**"
      ],
      "metadata": {
        "id": "2wrdK3oJ4Xhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "pknOP_N4rIUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a clean text column within each dataset for the model to use\n",
        "train_df['content'] = train_df['title'].astype(str) + \" \" + train_df['text'].astype(str)\n",
        "test_df['content'] = test_df['title'].astype(str) + \" \" + test_df['text'].astype(str)\n",
        "eval_df['content'] = eval_df['title'].astype(str) + \" \" + eval_df['text'].astype(str)\n",
        "\n",
        "# Check if column has been added\n",
        "print(train_df.columns)\n",
        "print(test_df.columns)\n",
        "print(eval_df.columns)"
      ],
      "metadata": {
        "id": "TFoP8IjzrIBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer() # Built in lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = str(text) # Ensure string\n",
        "    # 1. Lowercasing\n",
        "    text = text.lower()\n",
        "\n",
        "    # 2. Remove punctuation and special characters\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # 3. Tokenization & Stopword Removal & Lemmatization\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing\n",
        "print(\"Preprocessing training data...\")\n",
        "train_df['clean_text'] = train_df['content'].apply(preprocess_text)\n",
        "print(\"Preprocessing test data...\")\n",
        "test_df['clean_text'] = test_df['content'].apply(preprocess_text)\n",
        "print(\"Preprocessing evaluation data...\")\n",
        "eval_df['clean_text'] = eval_df['content'].apply(preprocess_text)\n",
        "\n",
        "print(\"Preprocessing complete.\")"
      ],
      "metadata": {
        "id": "blRy9Jqjqz58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up TF-IDF Vectorizer**"
      ],
      "metadata": {
        "id": "ZNdFswz-CnHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(max_features=5000) # Can adjust for memory size\n",
        "\n",
        "# Generating train and testing vectors\n",
        "x_train_vec = tfidf.fit_transform(train_df['clean_text'])\n",
        "x_test_vec = tfidf.transform(test_df['clean_text'])\n",
        "\n",
        "y_train = train_df['label']\n",
        "y_test = test_df['label']"
      ],
      "metadata": {
        "id": "RkgK5e3hCtOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating ML models**"
      ],
      "metadata": {
        "id": "TIn3WP4nqgvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating traditional Machne Learning models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
        "    \"Support Vector Machine\": SVC(kernel='linear')\n",
        "}"
      ],
      "metadata": {
        "id": "iS7ThEyoCtAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training and Testing**"
      ],
      "metadata": {
        "id": "NGa5eoVCrEIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "\n",
        "  # Training each model individially\n",
        "  model.fit(x_train_vec, y_train)\n",
        "  print(f\"Training {name} model\")\n",
        "\n",
        "  # Generating predictions with test set\n",
        "  y_pred = model.predict(x_test_vec)\n",
        "\n",
        "  # Evaluating the models accuracy, precision, recall and F1 score\n",
        "  results[name] = {\n",
        "      \"Accuracy\": accuracy_score(y_test, y_pred),\n",
        "      \"Precision\": precision_score(y_test, y_pred, average = 'weighted'),\n",
        "      \"Recall\": recall_score(y_test, y_pred, average = 'weighted'),\n",
        "      \"F1 Score\": f1_score(y_test, y_pred, average = 'weighted')\n",
        "  }\n",
        "\n",
        "  print(f\"Completed: {name}\\n\")"
      ],
      "metadata": {
        "id": "bjMkX_-IrG4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Displaying the Results of the Testing**"
      ],
      "metadata": {
        "id": "HbH-YR_fsNjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df_ml = pd.DataFrame(results).T\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
        "plot_data = results_df_ml[['Accuracy', 'F1 Score']].reset_index().melt(id_vars='index')\n",
        "plot_data.columns = ['Model', 'Metric', 'Score']\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "ax = sns.barplot(data=plot_data, x='Model', y='Score', hue='Metric')\n",
        "for container in ax.containers:\n",
        "    ax.bar_label(container, fmt='%.3f', padding=3)\n",
        "plt.title(\"Model Performance Comparison: Accuracy vs F1 Score\", fontsize=14, fontweight='bold', pad=20)\n",
        "plt.ylabel(\"Performance Score (0.0 - 1.0)\", fontsize=12, labelpad = 10)\n",
        "plt.xlabel(\"Machine Learning Models\", fontsize=12, labelpad = 10)\n",
        "plt.ylim(0, 1.1)\n",
        "plt.legend(title=\"Metrics\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aIAR-ndjsSIl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrices**"
      ],
      "metadata": {
        "id": "bhQy_199yMVS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, (name, model) in enumerate(models.items()):\n",
        "    y_pred = model.predict(x_test_vec)\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)\n",
        "    axes[i].set_title(f\"Confusion Matrix: {name}\", fontsize=14, pad = 10)\n",
        "    axes[i].set_xlabel(\"Predicted\")\n",
        "    axes[i].set_ylabel(\"Actual\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LALxO86cyQnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Applying BERT Model**"
      ],
      "metadata": {
        "id": "mTq9evbZ8Qfp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "5FfsmyTy4NdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NewsDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        text = str(self.texts[item])\n",
        "        label = self.labels[item]\n",
        "\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            return_token_type_ids=False,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt',\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ],
      "metadata": {
        "id": "B4REJb-Zs4Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenizer and BERT Model**"
      ],
      "metadata": {
        "id": "Qfz--B0r498o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "bert_model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "# Check for GPU and move model to GPU if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "bert_model.to(device)\n",
        "print(f\"BERT model moved to: {device}\")"
      ],
      "metadata": {
        "id": "36HJqqFK5C9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generating Data Loaders**"
      ],
      "metadata": {
        "id": "l4l7PFZtf73y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = NewsDataset(\n",
        "    train_df['content'].to_numpy(),\n",
        "    train_df['label'].to_numpy(),\n",
        "    tokenizer\n",
        ")\n",
        "test_dataset = NewsDataset(\n",
        "    test_df['content'].to_numpy(),\n",
        "    test_df['label'].to_numpy(),\n",
        "    tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "oDSchjhXhRkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Arguments**"
      ],
      "metadata": {
        "id": "88eflilFj8Y8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=16,\n",
        "    warmup_steps=50,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    eval_strategy=\"epoch\",\n",
        "    report_to = \"none\"\n",
        ")"
      ],
      "metadata": {
        "id": "v3ZXfrBVkJWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Trainer Setup**"
      ],
      "metadata": {
        "id": "YqQfqADKldQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=bert_model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "print(\"\\nStarting BERT Fine-Tuning\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "xlVDS2A-lfVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(test_dataset)\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "acc = accuracy_score(y_test, preds)\n",
        "precision = precision_score(y_test, preds)\n",
        "recall = recall_score(y_test, preds)\n",
        "f1 = f1_score(y_test, preds)\n",
        "\n",
        "print(\"--- Deep Learning (BERT) Results ---\")\n",
        "print(f\"Accuracy: {acc:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "mQfCgaR44Wy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**"
      ],
      "metadata": {
        "id": "79k9O-1Q430O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, preds)\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('BERT Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YvxtGXc648Jf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}